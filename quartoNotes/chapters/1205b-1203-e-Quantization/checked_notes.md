# **深度学习笔记：通信原理——量化器设计与Lloyd-Max算法**  
**课程名称**：通信原理  
**主讲人**：廉黎祥  
**授课时间**：第12周，2025年12月5日  
**整理目标**：将课堂语音转录稿与PPT内容融合，形成一份**知识准确、结构清晰、富有洞见**的深度学习笔记。本笔记不仅还原技术细节，更提炼教授的思维脉络、科研经验与教学智慧。

---

## **一、课程导引：从采样到编码的完整链条**

在进入“量化”这一核心环节前，我们需要明确它在整个通信系统中的位置和作用。

根据PPT图1所示的信号处理流程：
```
模拟波形 → [采样] → 模拟符号序列 → [量化] → 离散符号序列 → [离散信源编码] → 二进制比特流 → [传输]
```

- **采样（Sampling）**：将连续的时间信号转换为离散时间序列。
- **量化（Quantization）**：将每个采样点的**连续幅度值**转换为**有限个离散电平**。
- **编码（Coding）**：将离散的量化符号用二进制码字表示，实现数据压缩。

> 📌 **教授点拨**：  
> “我们今天开始讲量化器的部分。” —— 廉老师开门见山，强调了量化是连接模拟世界与数字世界的**关键桥梁**。它的设计直接决定了后续编码的效率与最终恢复信号的保真度。

![量化过程示意图。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_1.png)

---

## **二、量化基础：概念建模与数学框架**

### **1. 输入信号模型：独立同分布连续信源**

假设量化器的输入是一个理想离散无记忆信源（DMS），其输出序列为 $ u_1, u_2, \dots, u_k $。

- **建模假设**：每个输入符号 $ u $ 是一个**连续随机变量（Continuous R.V.）**，服从某个概率密度函数（PDF）$ f_U(u) $。
- **统计特性**：符号之间相互独立且同分布（i.i.d.）。
- **取值范围**：$ u \in [\min_u, \max_u] $，在一个连续区间内取值。

> 🔍 **纠错与澄清**：  
> 语音稿中多次出现“analog symbol”、“aog symbol”等表述，结合上下文及PPT图3，应统一纠正为 **“模拟符号（Analog Symbol）”** 或 **“连续随机变量”**。术语“loquence”应为 **“sequence”** 的语音识别错误。

![量化原理与误差分析。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_3.png)

---

### **2. 量化器的核心三要素**

一个标量量化器（Scalar Quantizer）由三个可设计的参数构成：

| 组件 | 符号 | 定义 |
| :--- | :--- | :--- |
| **量化级数** | $ M $ | 将输入幅度区间划分为 $ M $ 个子区间，决定输出字母表的大小。 |
| **量化区间** | $ R_j $ ($ j=1,\dots,M $) | 第 $ j $ 个子区间，即划分后的区域 $ R_j \subseteq [\min_u, \max_u] $。 |
| **量化代表点** | $ a_j $ ($ j=1,\dots,M $) | 第 $ j $ 个区间的代表值，也称“重构电平”或“质心”。 |

> ✅ **定义公式**：  
> 量化过程是一个映射函数：
> $$
> v = Q(u), \quad \text{其中} \quad v = a_j \quad \text{当且仅当} \quad u \in R_j
> $$
> 输出 $ v $ 是一个**离散随机变量**，其可能取值为集合 $ \{a_1, a_2, \dots, a_M\} $，称为量化器的**字母表（Alphabet）**。

![标量量化概念与过程。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_8.png)

---

### **3. 量化器输出的概率质量函数（PMF）**

给定输入分布 $ f_U(u) $ 和量化器设计 $ (M, \{R_j\}, \{a_j\}) $，我们可以计算输出 $ V $ 的概率质量函数 $ P_V(a_j) $。

$$
P_V(a_j) = \Pr(V = a_j) = \Pr(u \in R_j) = \int_{R_j} f_U(u)  du
$$

> 🧠 **深入理解**：  
> 教授特别指出：“大家可以看到我们的代表点，其实你到底选什么，其实他跟我们的一个质量函数是没有关系的。”  
> 这意味着：**量化区间的划分 $ \{R_j\} $ 决定了输出符号的概率分布，而代表点 $ \{a_j\} $ 不影响PMF**。  
> 这是一个重要的直觉：区间的“大小”和“位置”决定了哪个输出更可能出现。

---

## **三、量化性能的两大核心指标**

设计量化器时，我们始终关注两个相互制约的目标：

### **1. 信息熵 $ H(V) $：决定编码效率的下限**

量化输出 $ V $ 是一个离散信源，其信息熵为：
$$
H(V) = -\sum_{j=1}^M P_V(a_j) \log_2 P_V(a_j)
$$

- **意义**：根据香农信源编码定理，无损编码的平均码长 $ L $ 必须满足 $ L \geq H(V) $。
- **目标**：我们希望 $ H(V) $ 尽可能小，以实现更高的压缩率。

> 💡 **教授洞见**：  
> “我们希望这个速率能够尽可能的低……因为越低的话，我的编码效率越高。”  
> 这揭示了通信系统的根本矛盾之一：**保真度 vs. 效率**。量化越粗（$ M $ 小），$ H(V) $ 越小，编码越高效；但代价是失真增大。

![量化：目标、方法与失真度量。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_2.png)

---

### **2. 均方误差（MSE）：衡量量化失真的核心指标**

量化引入了不可逆的失真，其最常用的度量是**均方误差（Mean Squared Error, MSE）**，也称为**失真（Distortion）**。

#### **定义**
$$
D = \text{MSE} = \mathbb{E}[(u - v)^2] = \mathbb{E}[(u - Q(u))^2]
$$

该期望是对输入随机变量 $ u $ 的分布求的。

---

### **两种MSE计算方法及其深刻内涵**

教授详细推导了两种等价的MSE计算方法，这不仅是数学技巧，更蕴含了不同的思考视角。

#### **方法一：按量化区间分解积分**
$$
\text{MSE} = \sum_{j=1}^M \int_{R_j} (u - a_j)^2 f_U(u)  du
$$

> ✅ **思路解析**：  
> “把积分拆成每一个子区间的一个积分。” —— 这是最直观的物理意义：总误差等于每个区间内所有输入点与其代表点误差的加权和。

#### **方法二：利用条件期望（Conditional Expectation）**

$$
\text{MSE} = \sum_{j=1}^M \Pr(u \in R_j) \cdot \mathbb{E}[(u - a_j)^2 \mid u \in R_j]
$$

令：
- $ q_j = \Pr(u \in R_j) = \int_{R_j} f_U(u)  du $
- $ \text{MSE}_j = \mathbb{E}[(u - a_j)^2 \mid u \in R_j] $：**条件均方误差**

则：
$$
\text{MSE} = \sum_{j=1}^M q_j \cdot \text{MSE}_j
$$

> 🔍 **关键中间量：条件概率密度函数 $ f_j(u) $**  
> 给定 $ u \in R_j $，其条件PDF为：
> $$
> f_j(u) = 
> \begin{cases}
> \frac{f_U(u)}{q_j}, & u \in R_j \\
> 0, & \text{otherwise}
> \end{cases}
> $$  
> 
> **重要性质**：$ f_j(u) $ 在 $ R_j $ 上积分等于1，是一个合法的概率密度函数，对应于“已知输入落在第 $ j $ 个区间”这一条件下的新随机变量。

> 🎯 **方法对比与思想升华**：  
> 方法一从“空间分割”出发，方法二从“概率分解”出发。后者虽然计算结果相同，但它**显式地分离了概率权重 $ q_j $ 和局部失真 $ \text{MSE}_j $**，为我们优化提供了清晰的路径：要降低总MSE，要么让高概率区间的失真更小，要么让高失真区间的概率更低。

![通信系统均方误差分析。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_4.png)

---

## **四、经典案例分析：均匀量化器**

### **设定**
- **输入分布**：$ u \sim \text{Uniform}(0, 1) $，故 $ f_U(u) = 1 $。
- **量化器**：$ M=2 $，均匀划分区间，代表点取中点。
  - $ R_1 = [0, 0.5] $, $ a_1 = 0.25 $
  - $ R_2 = [0.5, 1] $, $ a_2 = 0.75 $

### **计算过程（两种方法验证）**

#### **方法一：直接积分**
$$
\begin{align*}
\text{MSE} &= \int_0^{0.5} (u - 0.25)^2 \cdot 1  du + \int_{0.5}^1 (u - 0.75)^2 \cdot 1  du \\
&= \left[ \frac{(u-0.25)^3}{3} \right]_0^{0.5} + \left[ \frac{(u-0.75)^3}{3} \right]_{0.5}^1 \\
&= \frac{1}{48} + \frac{1}{48} = \frac{1}{24}
\end{align*}
$$

#### **方法二：条件期望**
- $ q_1 = q_2 = 0.5 $
- 条件PDF：$ f_1(u) = 2 $ on $ [0,0.5] $, $ f_2(u) = 2 $ on $ [0.5,1] $
- 条件MSE：
  $$
  \text{MSE}_1 = \int_0^{0.5} (u - 0.25)^2 \cdot 2  du = 2 \cdot \frac{1}{48} = \frac{1}{24}
  $$
  （注意：这是条件期望，需乘以 $ q_j $）
- 总MSE：$ \text{MSE} = 0.5 \times \frac{1}{24} + 0.5 \times \frac{1}{24} = \frac{1}{24} $

> ✅ **结论**：两种方法结果一致，验证了理论的正确性。

![量化器均方误差分析。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_5.png)

---

### **推广：一般均匀量化器的MSE**

考虑一个更一般的均匀量化器：
- 输入 $ u \in [a, b] $，均匀分布。
- 划分为 $ M $ 个等宽区间，宽度 $ \Delta = \frac{b-a}{M} $。
- 代表点 $ a_j $ 取各区间中点。

通过类似计算（教授引导做变量替换 $ u' = u - a_j $）可得：

$$
\boxed{\text{MSE} = \frac{\Delta^2}{12}}
$$

> 🔥 **核心洞察**：  
> 教授在此处揭示了一个深刻的**权衡（Trade-off）**：
>
> - 当 $ M \uparrow $（量化级数增多），$ \Delta \downarrow $，MSE $ \downarrow $，**失真减小，可靠性提高**。
> - 但同时，$ H(V) \approx \log_2 M \uparrow $，**信息熵增大，要求更高的编码速率，效率降低**。
>
> > 💬 **教授总结**：“所以可以看到我们的编码器的编码速率和我们的量化器的量化误差之间其实是会有一个冲突。”  
> 这正是通信系统设计的核心挑战：**如何在可靠性和效率之间取得最佳平衡**。

---

## **五、最优量化器设计：Lloyd-Max算法**

### **问题定义：最小化MSE**

给定输入PDF $ f_U(u) $ 和量化级数 $ M $，如何设计 $ \{R_j\} $ 和 $ \{a_j\} $ 使得MSE最小？

这是一个联合优化问题。Lloyd-Max算法将其分解为两个交替进行的子问题。

![量化理论与算法](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_6.png)

---

### **子问题1：给定代表点 $ \{a_j\} $，如何划分最优区间 $ \{R_j\} $?**

**原则**：采用“最近邻准则（Nearest Neighbor Rule）”。

- 对任意输入 $ u $，应将其分配给距离最近的代表点 $ a_j $。
- 相邻区间 $ R_j $ 和 $ R_{j+1} $ 的边界 $ b_j $ 应位于 $ a_j $ 和 $ a_{j+1} $ 的中点：
  $$
  \boxed{b_j = \frac{a_j + a_{j+1}}{2}}
  $$

> ✅ **直观解释**：这就是Voronoi图的思想，确保每个点都去“最近的家”。

![标量量化边界计算](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_10.png)

---

### **子问题2：给定区间 $ \{R_j\} $，如何选择最优代表点 $ \{a_j\} $?**

**原则**：选择使该区间内条件MSE最小的点。

对于第 $ j $ 个区间，最小化：
$$
\text{MSE}_j = \mathbb{E}[(u - a_j)^2 \mid u \in R_j]
$$

通过求导或配方法可知，最优解为该区间内 $ u $ 的**条件期望**：

$$
\boxed{a_j^* = \mathbb{E}[u \mid u \in R_j] = \frac{1}{q_j} \int_{R_j} u f_U(u)  du}
$$

> ✅ **几何意义**：$ a_j $ 应取为该区间在概率密度“重心”上的投影，即**质心（Centroid）**。

![标量量化概念与公式推导。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_11.png)

![标量量化原理与公式推导。](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_12.png)

---

### **Lloyd-Max算法：迭代优化**

1. **初始化**：随机选择一组初始代表点 $ \{a_j^{(0)}\} $。
2. **迭代**：
   - **Step A (更新区间)**：根据当前 $ \{a_j\} $，用中点规则划分 $ \{R_j\} $。
   - **Step B (更新代表点)**：根据当前 $ \{R_j\} $，计算每个区间的条件期望作为新的 $ \{a_j\} $。
3. **终止**：当MSE变化小于阈值，或 $ \{a_j\} $ 收敛时停止。

> ⚠️ **重要提醒**：  
> 教授特别强调：“因为它其实是一个非凸的一个优化问题……你有可能落到某一个local optimum上。”  
> 因此，Lloyd-Max算法找到的是**局部最优解（Local Optimum）**，而非全局最优。其收敛性依赖于初始值的选择。

> 📚 **历史背景**：  
> Lloyd-Max算法由Stuart Lloyd（1957）和Joel Max（1960）分别独立提出，是标量量化领域的奠基性工作。尽管有局限性，它因简单有效而被广泛应用。

![Lloyd-Max算法简介](https://raw.githubusercontent.com/yansumm/picbed/master/class/EE140/1205b-1203-e-Quantization/page_13.png)

---

## **六、两种设计哲学的对比**

教授最后提出了两种不同的量化器设计范式：

| 范式 | 目标 | 约束 | 核心思想 |
| :--- | :--- | :--- | :--- |
| **最小MSE量化** | 最小化 $ \text{MSE} $ | 给定 $ M $ | 优先保证信号保真度。 |
| **熵约束量化** | 最小化 $ \text{MSE} $ | 给定编码速率 $ R $，要求 $ H(V) = R $ | 优先保证通信效率，在固定码率下追求最佳质量。 |

> 🔄 **内在联系**：  
> 在第二种范式中，约束 $ H(V) = R $ 实际上限制了 $ \{R_j\} $ 的设计（因其决定PMF），而 $ \{a_j\} $ 仍按条件期望设计。这体现了**分而治之**的设计哲学。

---

## **七、总结与启示**

### **知识要点回顾**
1. 量化是将连续幅度离散化的关键步骤。
2. 量化器由 $ M $、$ \{R_j\} $、$ \{a_j\} $ 三要素定义。
3. 性能由 $ H(V) $（编码效率）和 MSE（失真）共同衡量，二者存在根本权衡。
4. Lloyd-Max算法通过“最近邻划分”和“质心代表”两个准则，迭代求解近似最优量化器。

### **超越公式的智慧**
- **工程思维**：没有绝对的“最优”，只有“在约束下的最优”。设计总是关于权衡的艺术。
- **数学工具的力量**：条件概率、期望、优化分解等工具，将复杂的工程问题转化为可计算的数学形式。
- **迭代思想**：面对复杂非凸问题，Lloyd-Max展示了“逐步改进”策略的强大生命力。

> 🎓 **结语**：  
> 正如教授所言，这节课不仅是教我们如何算MSE，更是引导我们思考：**如何为一个模糊的问题建立精确的数学模型，并通过严谨的逻辑找到可行的解决方案**。这才是工程教育的精髓所在。